llms:
  text_generation:
    default: claude-3-5-sonnet-20240620
    available:
      # Anthropic models
      - claude-3-5-sonnet-20240620:
          url: https://api.anthropic.com/v1/messages
          max_tokens: 200000
          output_tokens: 8192
          temperature: 0.7
          capabilities: ["multilingual", "vision"]
          latency: "fast"
          cost_input: 3.00
          cost_output: 15.00
      - claude-3-opus-20240229:
          url: https://api.anthropic.com/v1/messages
          max_tokens: 200000
          output_tokens: 4096
          temperature: 0.7
          capabilities: ["multilingual", "vision"]
          latency: "moderately_fast"
          cost_input: 15.00
          cost_output: 75.00
      - claude-3-sonnet-20240229:
          url: https://api.anthropic.com/v1/messages
          max_tokens: 200000
          output_tokens: 4096
          temperature: 0.7
          capabilities: ["multilingual", "vision"]
          latency: "fast"
          cost_input: 3.00
          cost_output: 15.00
      - claude-3-haiku-20240307:
          url: https://api.anthropic.com/v1/messages
          max_tokens: 200000
          output_tokens: 4096
          temperature: 0.7
          capabilities: ["multilingual", "vision"]
          latency: "fastest"
          cost_input: 0.25
          cost_output: 1.25
      
      # Google Gemini models
      - gemini-1.5-pro:
          url: https://generativelanguage.googleapis.com/v1/models/gemini-1.5-pro:generateContent
          max_tokens: 32768
          temperature: 0.7
          capabilities: ["audio", "images", "videos", "text"]
          description: "Complex reasoning tasks"
      - gemini-1.5-flash:
          url: https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent
          max_tokens: 32768
          temperature: 0.7
          capabilities: ["audio", "images", "videos", "text"]
          description: "Fast and versatile performance"
      - gemini-1.0-pro:
          url: https://generativelanguage.googleapis.com/v1/models/gemini-1.0-pro:generateContent
          max_tokens: 32768
          temperature: 0.7
          capabilities: ["text"]
          description: "Natural language tasks, multi-turn text and code chat"
      - text-embedding-004:
          url: https://generativelanguage.googleapis.com/v1/models/text-embedding-004:embedText
          description: "Text embeddings"
      - aqa:
          url: https://generativelanguage.googleapis.com/v1/models/aqa:generateContent
          description: "Source-grounded answers to questions"
      
      # OpenAI models
      - gpt-4:
          url: https://api.openai.com/v1/chat/completions
          max_tokens: 8192
          temperature: 0.7
      - gpt-3.5-turbo:
          url: https://api.openai.com/v1/chat/completions
          max_tokens: 4096
          temperature: 0.7
      
      # GroqCloud models
      - llama-3.1-405b-reasoning:
          url: https://api.groq.com/openai/v1/chat/completions
          max_tokens: 131072
          temperature: 0.7
      - llama-3.1-70b-versatile:
          url: https://api.groq.com/openai/v1/chat/completions
          max_tokens: 131072
          temperature: 0.7
      - llama-3.1-8b-instant:
          url: https://api.groq.com/openai/v1/chat/completions
          max_tokens: 131072
          temperature: 0.7
      - llama3-groq-70b-8192-tool-use-preview:
          url: https://api.groq.com/openai/v1/chat/completions
          max_tokens: 8192
          temperature: 0.7
      - llama3-groq-8b-8192-tool-use-preview:
          url: https://api.groq.com/openai/v1/chat/completions
          max_tokens: 8192
          temperature: 0.7
      - llama-guard-3-8b:
          url: https://api.groq.com/openai/v1/chat/completions
          max_tokens: 8192
          temperature: 0.7
      - llama3-70b-8192:
          url: https://api.groq.com/openai/v1/chat/completions
          max_tokens: 8192
          temperature: 0.7
      - llama3-8b-8192:
          url: https://api.groq.com/openai/v1/chat/completions
      - claude-instant-1.2:
          url: https://api.anthropic.com/v1/messages
          max_tokens: 4096
          temperature: 0.7
      - gpt-4o:
          url: https://api.openai.com/v1/chat/completions
          model: gpt-4o-mini
          max_tokens: 150
          temperature: 0.7
          example_response:
            id: "chatcmpl-abc123"
            object: "chat.completion"
            created: 1677858242
            model: "gpt-4o-mini"
            usage:
              prompt_tokens: 13
              completion_tokens: 7
              total_tokens: 20
            choices:
              - message:
                  role: "assistant"
                  content: "\n\nThis is a test!"
                logprobs: null
                finish_reason: "stop"
                index: 0
      - gpt-4:
          url: https://api.openai.com/v1/chat/completions
          model: gpt-4
          max_tokens: 200
          temperature: 0.8
      - gpt-3.5-turbo:
          url: https://api.openai.com/v1/chat/completions
          model: gpt-3.5-turbo
          max_tokens: 100
          temperature: 0.9

  image_generation:
    default: stable-diffusion
    available:
      - stable-diffusion:
          url: https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image

  audio:
    speech_to_text:
      url: https://api.openai.com/v1/audio/transcriptions
      models:
        - whisper-1
      file_formats:
        - mp3
        - mp4
        - mpeg
        - mpga
        - m4a
        - wav
        - webm
      max_file_size: 25000000  # 25 MB
      parameters:
        file: required
        model: required
        prompt: optional
        response_format:
          type: optional
          default: json
          options:
            - json
            - text
            - srt
            - verbose_json
            - vtt
        temperature:
          type: optional
          default: 0
          range:
            min: 0
            max: 1
        language: optional
    text_to_speech:
      url: https://api.openai.com/v1/audio/speech
      models:
        - tts-1
        - tts-1-hd
      parameters:
        model: required
        input: required
        voice:
          type: required
          options:
            - alloy
            - echo
            - fable
            - onyx
            - nova
            - shimmer
        response_format:
          type: optional
          default: mp3
          options:
            - mp3
            - opus
            - aac
            - flac
        speed:
          type: optional
          default: 1.0
          range:
            min: 0.25
            max: 4.0

api_keys:
  anthropic: ANTHROPIC_API_KEY
  openai: OPENAI_API_KEY
  groq: GROQ_API_KEY
  gemini: GEMINI_API_KEY

default_params:
  max_retries: 3
  timeout: 30
  retry_delay: 1
  max_tokens: 2048
  temperature: 0.7